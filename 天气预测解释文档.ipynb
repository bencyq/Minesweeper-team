{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 天气预测解释文档"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 爬虫模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 导入所需要的包\n",
    "导入csv、requests、json包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 设置请求头"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)Chrome/90.0.4430.85 Safari/537.36\",\n",
    "    \"Host\": \" tianqiapi.com\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 设置基本属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"https://v0.yiketianqi.com/api?version=history&appid=88626512&appsecret=N49775tS&city=\"\n",
    "cities = ['杭州', '宁波', '温州', '嘉兴', '湖州', '绍兴', '金华', '衢州', '舟山', '台州', '丽水']# 所爬取的城市列表\n",
    "b_year = \"&year=\"# 年份\n",
    "start_year = 2019\n",
    "end_year = 2020\n",
    "b_month = \"&month=\"# 月份\n",
    "start_month = 1\n",
    "end_month = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 进行爬取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHTMLText(url):\n",
    "    try:\n",
    "        response = requests.get(url)# 发出请求\n",
    "        response.raise_for_status()\n",
    "        response.encoding = response.apparent_encoding\n",
    "        return response.text\n",
    "    except:\n",
    "        return \"error in getHTMLText\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 对爬取的数据处理\n",
    "将获得的json格式的数据通过循环结构依次处理成csv格式的文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(start_year, end_year + 1):\n",
    "    with open('data'+str(year)+'.csv', 'w', newline=\"\") as file:# 生成文件\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(\n",
    "            ['city', 'ymd', 'bWendu', 'yWendu', 'tianqi', 'fengxiang', 'fengli', 'aqi', 'aqiInfo', 'aqiLevel'])\n",
    "        for city in cities:\n",
    "            for month in range(start_month, end_month + 1):\n",
    "                url = str(base + city + b_year + str(year) + b_month + str(month))\n",
    "                data = json.loads(getHTMLText(url))# 爬取并转换\n",
    "                for i in range(0, len(data['data'])):\n",
    "                    writer.writerow(\n",
    "                        [data['city'], data['data'][i]['ymd'], data['data'][i]['bWendu'], data['data'][i]['yWendu'],\n",
    "                         data['data'][i]['tianqi'], data['data'][i]['fengxiang'], data['data'][i]['fengli'],\n",
    "                         data['data'][i]['aqi'], data['data'][i]['aqiInfo'], data['data'][i]['aqiLevel']])# 存入数据\n",
    "                # print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 画图模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 导入包\n",
    "导入了numpy、pandas、matplotlib包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import MultipleLocator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 定义画图的函数\n",
    "设置一个 15×8 的画布，并设置为折线图，接下来设置了一系列图表的参数，并且保存到当前文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(city, h_temp_arr, l_temp_arr):\n",
    "    for i in range(31):  # 把气温的数据从str 转化为 int\n",
    "        h_temp_arr[i] = int(h_temp_arr[i][:-1])\n",
    "        l_temp_arr[i] = int(l_temp_arr[i][:-1])\n",
    "\n",
    "    date = []\n",
    "    for i in range(1, 32):  # 设定日期数组\n",
    "        date.append(i)\n",
    "\n",
    "    # 正式画图\n",
    "    plt.rcParams['font.sans-serif'] = 'SimHei'  # 用来设置字体样式\n",
    "    plt.rcParams['axes.unicode_minus'] = False  # 设置正常显示符号\n",
    "    plt.style.use('fivethirtyeight')  # 设置主题\n",
    "    fig = plt.figure(figsize=(15, 8))\n",
    "    plt.title(city + ' 三月份最高温度/最低温度折线图')\n",
    "    plt.xlabel('日期', fontsize=14)\n",
    "    plt.ylabel('温度/℃', fontsize=14)\n",
    "    plt.xlim(0.5, 31.5)\n",
    "    plt.plot(date, h_temp_arr, color='deeppink', linewidth=1.5, linestyle='--', label='每日最高气温', marker='o')\n",
    "    plt.plot(date, l_temp_arr, color='darkblue', linewidth=1.5, linestyle=':', label='每日最低气温', marker='+')\n",
    "    plt.legend()  # 显示 x、y 轴说明\n",
    "    plt.grid()  # 显示网格线\n",
    "    # plt.show()\n",
    "    plt.savefig(city + \" 三月份气温折线图.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 正式画图\n",
    "读入数据，并且依次筛选出城市和温度数据，按照各个城市进行画图（调用画图的函数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "df = pd.read_csv('data.csv', encoding='gbk')\n",
    "h_temp_df = pd.DataFrame(df, columns=['city', 'bWendu'])  # 筛选出每日最高气温\n",
    "l_temp_df = pd.DataFrame(df, columns=['city', 'yWendu'])  # 筛选出每日最低气温\n",
    "cities = ['杭州', '宁波', '温州', '嘉兴', '湖州', '绍兴', '金华', '衢州', '舟山', '台州', '丽水']\n",
    "for city in cities:\n",
    "    h_temp_arr = np.array(h_temp_df.loc[h_temp_df['city'] == city])\n",
    "    l_temp_arr = np.array(l_temp_df.loc[l_temp_df['city'] == city])\n",
    "    draw(city, h_temp_arr[:, 1], l_temp_arr[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 线性回归模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 导入包\n",
    "导入pandas、numpy、sklean、torch、matplotlib包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 定义模型的函数\n",
    "通过 **torch.nn.linear** 模块，我们可以快速、简单地定义一个线性回归的模型。\n",
    "\n",
    "该线性回归模型的输入输出维度分别为49，7，循环次数为8001次，学习率为0.001\n",
    "\n",
    "我们采用了 MSELoss 的方法来计算 loss，并采用 SGD 方案作为参数更新模式。\n",
    "\n",
    "接下来在循环结构中，我们通过循环不断的梯度清零、标签预测、loss计算、梯度下降、参数更新来获取最优的参数。\n",
    "\n",
    "并且每隔100个 epoch 会输出一次 train_loss 和 test_loss，通过比对两者是否趋于临界值和是否反弹来判断模型的拟合程度。\n",
    "\n",
    "参数更新完毕后，会在控制台输出某一天的预测结果和实际结果（来判断模型的好坏），并保存模型到当前文件夹。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(x, y, test_x, test_y, D_inputs=49, D_outputs=7, epoch=10001, temp='none', lr=0.0001):\n",
    "    # 构建模型\n",
    "    model = nn.Sequential(nn.Linear(D_inputs, D_outputs))\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    print(temp)\n",
    "    # 训练模型\n",
    "    for t in range(epoch):\n",
    "        # train_set\n",
    "        model.zero_grad()  # 梯度清零\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "\n",
    "        # test_set\n",
    "        y_pred_test = model(test_x)\n",
    "        test_loss = loss_fn(y_pred_test, test_y)\n",
    "\n",
    "        # 参数更新\n",
    "        with torch.no_grad():  # 参数更新方式\n",
    "            for parm in model.parameters():\n",
    "                parm -= lr * parm.grad\n",
    "        if t % 100 == 0:\n",
    "            print('iter: {}\\ttrain_loss: {}\\ttest_loss: {}'.format(t, loss, test_loss))\n",
    "\n",
    "    out = model(x[666, :])\n",
    "    out_pred = model(test_x[-1, :])\n",
    "    print(out)\n",
    "    print(y[666])\n",
    "    print('pred:{}'.format(out_pred))\n",
    "    torch.save(model.state_dict(), '{}.pt'.format(temp))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 用来预测的函数\n",
    "1. 定义模型\n",
    "2. 获取保存在本地的模型参数，重构模型\n",
    "3. 获取3月25号到3月31号的天气数据，准备预测\n",
    "4. 根据11个地级市各自预测的结果，求出4月1号到4月7号，每天最高温和最低温的平均值，并保存到字典\n",
    "5. 打印保存的字典\n",
    "6. 根据保存的数据，制作一张四月份天气预测折线图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(pred_x_set):\n",
    "    # 构建模型\n",
    "    model_high = nn.Sequential(nn.Linear(D_inputs, D_outputs))\n",
    "    model_low = nn.Sequential(nn.Linear(D_inputs, D_outputs))\n",
    "    model_high.load_state_dict(torch.load('high.pt'))\n",
    "    model_low.load_state_dict(torch.load('low.pt'))\n",
    "    day_h = {}  # 收集每天的平均温度（最高/最低）\n",
    "    day_l = {}  # 收集每天的平均温度（最高/最低）\n",
    "    for i in range(7):\n",
    "        name1 = '4月{}号最高温度'.format(i + 1)\n",
    "        name2 = '4月{}号最低温度'.format(i + 1)\n",
    "        day_h[name1] = 0\n",
    "        day_l[name2] = 0\n",
    "        for city in cities:\n",
    "            day_h[name1] += model_high(pred_x_set[city]).detach().numpy()[i]\n",
    "            day_l[name2] += model_low(pred_x_set[city]).detach().numpy()[i]\n",
    "        day_h[name1] /= 11\n",
    "        day_h[name1] = int(day_h[name1] + 0.5)\n",
    "        day_l[name2] /= 11\n",
    "        day_l[name2] = int(day_l[name2] + 0.5)\n",
    "\n",
    "    print(day_h)\n",
    "    print(day_l)\n",
    "\n",
    "\n",
    "    x=list(day_h.keys())\n",
    "    for i in range(len(x)):\n",
    "        x[i]=x[i][:-4]\n",
    "    y_h=day_h.values()\n",
    "    y_l=day_l.values()\n",
    "    # 画一个折线图\n",
    "    plt.rcParams['font.sans-serif'] = 'SimHei'  # 用来设置字体样式\n",
    "    plt.rcParams['axes.unicode_minus'] = False  # 设置正常显示符号\n",
    "    plt.style.use('fivethirtyeight')  # 设置主题\n",
    "    fig = plt.figure(figsize=(15, 9))\n",
    "    plt.title('四月一号到七号最高温度/最低温度折线图')\n",
    "    plt.xlabel('日期', fontsize=14)\n",
    "    plt.xticks(rotation=45)  # 使x轴坐标文本反转45°\n",
    "    plt.ylabel('温度/℃', fontsize=14)\n",
    "    plt.ylim(15,30)\n",
    "    # plt.xlim(0.5, 31.5)\n",
    "    plt.plot(x, y_h, color='deeppink', linewidth=1.5, linestyle='--', label='每日最高气温', marker='o')\n",
    "    plt.plot(x, y_l, color='darkblue', linewidth=1.5, linestyle=':', label='每日最低气温', marker='+')\n",
    "    plt.legend()  # 显示 x、y 轴说明\n",
    "    plt.grid()  # 显示网格线\n",
    "    # plt.show()\n",
    "    plt.savefig('四月份气温预测图')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 定义数据预处理的函数\n",
    "由于读取进来的数据包含文本而并非全都是数字，我们先将文本依次转换为数字权重，并实现数据集的归一化，来确保模型训练时参数更新的稳定性，由此我们得到了 732×7 的数据集矩阵。\n",
    "\n",
    "我们的做法是用前七天的天气数据，预测后七天的最高温/最低温，也就是说每七天的天气数据作为一个样本，即一个7×7的矩阵为一个样本。\n",
    "\n",
    "为了方便模型处理，我们将7×7的矩阵压扁为1×49的向量。由于数据集较小（只有两年的天气数据），我们采取了1-7号作为样本1、2-8号作为样本2这样的策略来扩充数据集，这样我们就可以得到一个7898×49的数据集矩阵（相比于1-7号作为样本1，8-14号作为样本2的做法，我们采取的做法能大大扩充数据集，保证模型的鲁棒性），这样一个二维矩阵就能够直接进入模型运算了。\n",
    "最终，我们将处理好的数据，从numpy格式依次转成tensor格式、torch.float32格式，并将数据返回。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(x):\n",
    "    # 具体的天气数据预处理函数，把温度、天气、风向等数据转化为数字\n",
    "    for i in range(0, len(x[:, 0])):\n",
    "        # 对最高温度进行处理\n",
    "        x[:, 0][i] = float(x[:, 0][i][:-1])\n",
    "        # 对最低温度进行处理\n",
    "        x[:, 1][i] = float(x[:, 1][i][:-1])\n",
    "        # 对天气情况进行处理\n",
    "        judge = 0\n",
    "        times = 0\n",
    "        if '暴雨' in x[:, 2][i]:\n",
    "            judge += 0\n",
    "            times += 1\n",
    "        if '大雨' in x[:, 2][i]:\n",
    "            judge += 1\n",
    "            times += 1\n",
    "        if '雷阵雨' in x[:, 2][i]:\n",
    "            judge += 2\n",
    "            times += 1\n",
    "        if '中雨' in x[:, 2][i]:\n",
    "            judge += 3\n",
    "            times += 1\n",
    "        if '小雨' in x[:, 2][i]:\n",
    "            judge += 4\n",
    "            times += 1\n",
    "        if '小雪' in x[:, 2][i]:\n",
    "            judge += 5\n",
    "            times += 1\n",
    "        if '阵雪' in x[:, 2][i]:\n",
    "            judge += 6\n",
    "            times += 1\n",
    "        if '雨夹雪' in x[:, 2][i]:\n",
    "            judge += 7\n",
    "            times += 1\n",
    "        if '雾' or '霾' in x[:, 2][i]:\n",
    "            judge += 8\n",
    "            times += 1\n",
    "        if '阴' in x[:, 2][i]:\n",
    "            judge += 9\n",
    "            times += 1\n",
    "        if '多云' in x[:, 2][i]:\n",
    "            judge += 10\n",
    "            times += 1\n",
    "        if '晴' in x[:, 2][i]:\n",
    "            judge += 10\n",
    "            times += 1\n",
    "\n",
    "        x[:, 2][i] = judge / times\n",
    "        # 对风向进行处理\n",
    "        judge = 0\n",
    "        if '北风' in x[:, 3][i]:\n",
    "            judge = 0\n",
    "        if '东北风' in x[:, 3][i]:\n",
    "            judge = 0.5\n",
    "        if '东风' in x[:, 3][i]:\n",
    "            judge = 1\n",
    "        if '东南风' in x[:, 3][i]:\n",
    "            judge = 1.5\n",
    "        if '南风' in x[:, 3][i]:\n",
    "            judge = 2\n",
    "        if '西南风' in x[:, 3][i]:\n",
    "            judge = 2.5\n",
    "        if '西风' in x[:, 3][i]:\n",
    "            judge = 3\n",
    "        if '西北风' in x[:, 3][i]:\n",
    "            judge = 3.5\n",
    "        x[:, 3][i] = judge\n",
    "        # 对风力进行处理\n",
    "        judge = 0\n",
    "        if '微' in x[:, 4][i]:\n",
    "            judge = 0\n",
    "        if '1级' in x[:, 4][i]:\n",
    "            judge = 1\n",
    "        if '2级' in x[:, 4][i]:\n",
    "            judge = 2\n",
    "        if '3级' in x[:, 4][i]:\n",
    "            judge = 3\n",
    "        if '4级' in x[:, 4][i]:\n",
    "            judge = 4\n",
    "        if '5级' in x[:, 4][i]:\n",
    "            judge = 5\n",
    "        if '6级' in x[:, 4][i]:\n",
    "            judge = 6\n",
    "        if '7级' in x[:, 4][i]:\n",
    "            judge = 7\n",
    "        if '8级' in x[:, 4][i]:\n",
    "            judge = 8\n",
    "        x[:, 4][i] = float(judge)\n",
    "        # 对空气指数进行处理\n",
    "        x[:, 5][i] = float(x[:, 5][i])\n",
    "        # 对空气质量进行处理\n",
    "        judge = 0\n",
    "        if '优' in x[:, 6][i]:\n",
    "            judge = 0\n",
    "        if '良' in x[:, 6][i]:\n",
    "            judge = 1\n",
    "        if '轻度' in x[:, 6][i]:\n",
    "            judge = 2\n",
    "        if '中度' in x[:, 6][i]:\n",
    "            judge = 3\n",
    "        x[:, 6][i] = float(judge)\n",
    "    x = x.astype(float)  # x 处理前是 pandas 的 object 类型\n",
    "\n",
    "    # 实现数据的标准化\n",
    "    '''\n",
    "    sklearn.preprocessing.scale() 实现数据标准化\n",
    "    参数解释：\n",
    "        X : {array-like, sparse matrix}\n",
    "        要标准化的数据，numpy的array类数据。\n",
    "\n",
    "        axis : int (0 by default)\n",
    "        处理哪个维度，0表示处理横向的数据（行）， 1表示处理纵向的数据（列），默认为0\n",
    "\n",
    "        with_mean : boolean, True by default\n",
    "        是否中心化。\n",
    "\n",
    "        with_std : boolean, True by default\n",
    "        是否标准化。\n",
    "\n",
    "        copy : boolean, optional, default True\n",
    "        是否复制。\n",
    "    '''\n",
    "    x_scale = preprocessing.scale(x, axis=0, with_mean=True, with_std=True, copy=True)\n",
    "\n",
    "    # 实现数据的分类处理\n",
    "    '''\n",
    "    一共31*12个数据，我的做法是：取1-7天的天气数据，预测8-14天的温度信息\n",
    "    依此类推，取2-8天的数据，预测9-15天的温度\n",
    "    易得，我可以组成18组数据作为我的 train set\n",
    "    为了方便 torch.from_numpy()运算（只支持2维数组），把1-7天的7×7的矩阵压扁成1×49的矩阵\n",
    "    x_data 为353批次，每批次包含七天天气数据的test集，即353*49的矩阵\n",
    "    y_h_data和y_l_data为353批次，每批次包含七天的温度数据的val集，即353*7矩阵\n",
    "    fianl_data为3月25-31的数据，用来预测4月1号到7号的数据\n",
    "    '''\n",
    "    x_data = []\n",
    "    for i in range(0, x_scale.shape[0] - 13):\n",
    "        x_data.append(np.append([], x_scale[i:i + 7, :]))\n",
    "    x_data = np.array(x_data)\n",
    "\n",
    "    y_h_data = []\n",
    "    for i in range(7, x_scale.shape[0] - 6):\n",
    "        y_h_data.append(np.append([], x[i:i + 7, 0]))\n",
    "    y_h_data = np.array(y_h_data)\n",
    "\n",
    "    y_l_data = []\n",
    "    for i in range(7, x_scale.shape[0] - 6):\n",
    "        y_l_data.append(np.append([], x[i:i + 7, 1]))\n",
    "    y_l_data = np.array(y_l_data)\n",
    "\n",
    "    final_data = np.array([np.append([], x_scale[x_scale.shape[0] - 7:x_scale.shape[0], :])])\n",
    "    final_data = final_data[0]  # 2021年3月25-31号数据\n",
    "\n",
    "    # 把数据从 numpy 格式转化为 Tensor\n",
    "    x_data = torch.from_numpy(x_data)\n",
    "    y_h_data = torch.from_numpy(y_h_data)\n",
    "    y_l_data = torch.from_numpy(y_l_data)\n",
    "    final_data = torch.from_numpy(final_data)\n",
    "\n",
    "    # 设定tensor格式\n",
    "    x_data = torch.tensor(x_data, dtype=torch.float32)\n",
    "    y_h_data = torch.tensor(y_h_data, dtype=torch.float32)\n",
    "    y_l_data = torch.tensor(y_l_data, dtype=torch.float32)\n",
    "    final_data = torch.tensor(final_data, dtype=torch.float32)\n",
    "\n",
    "    return x_data, y_h_data, y_l_data, final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 设置超参\n",
    "将模型的参数设置为49×7，学习率设为0.001，次数设置为8001次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_inputs = 49  # 七天的数据都作为一个样本，产生7*7=49个特征参数\n",
    "D_outputs = 7\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epoches = 8001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 正式进行天气预测\n",
    "调用数据预处理函数，依次处理对 train_set、test_set、pred_set 进行数据预处理\n",
    "\n",
    "调用线性回归函数，并传入超参\n",
    "\n",
    "调用预测模块，生成结果，并制作成折线图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global cities\n",
    "cities = ['杭州', '宁波', '温州', '嘉兴', '湖州', '绍兴', '金华', '衢州', '舟山', '台州', '丽水']\n",
    "\n",
    "# train_set\n",
    "train_df = pd.read_csv('data2019-2020.csv', encoding='gbk').fillna(str(0))\n",
    "train_x_set = torch.Tensor()\n",
    "train_y_h_set = torch.Tensor()\n",
    "train_y_l_set = torch.Tensor()\n",
    "\n",
    "# test_set\n",
    "test_df = pd.read_csv('data.csv', encoding='gbk').fillna(str(0))\n",
    "test_x_set = torch.Tensor()\n",
    "test_y_h_set = torch.Tensor()\n",
    "test_y_l_set = torch.Tensor()\n",
    "\n",
    "# pred_test\n",
    "pred_x_set = {}\n",
    "\n",
    "for city in cities:\n",
    "    # train_set\n",
    "    # 读取数据，并把前两列数据裁剪掉\n",
    "    train_data = np.array(train_df.loc[train_df['city'] == city])[:, 2:-1]\n",
    "    # 具体的天气数据预处理函数，把温度、天气、风向等数据转化为数字\n",
    "    [x, y_h, y_l, _] = data_process(train_data)\n",
    "    train_x_set = torch.cat([train_x_set, x], dim=0)\n",
    "    train_y_h_set = torch.cat([train_y_h_set, y_h], dim=0)\n",
    "    train_y_l_set = torch.cat([train_y_l_set, y_l], dim=0)\n",
    "\n",
    "    # test_set and pred_set\n",
    "    test_data = np.array(test_df.loc[test_df['city'] == city])[:, 2:-1]\n",
    "    [x, y_h, y_l, final_x] = data_process(test_data)\n",
    "    test_x_set = torch.cat([test_x_set, x], dim=0)\n",
    "    test_y_h_set = torch.cat([test_y_h_set, y_h], dim=0)\n",
    "    test_y_l_set = torch.cat([test_y_l_set, y_l], dim=0)\n",
    "    pred_x_set[city] = final_x\n",
    "\n",
    "print(train_x_set.shape)\n",
    "print(train_y_h_set.shape)\n",
    "linear_regression(train_x_set, train_y_h_set, test_x_set, test_y_h_set, epoch=num_epoches, temp='high',\n",
    "                   lr=learning_rate)\n",
    "linear_regression(train_x_set, train_y_l_set, test_x_set, test_y_l_set, epoch=5801, temp='low',\n",
    "                   lr=learning_rate)\n",
    "\n",
    "%matplotlib inline\n",
    "pred(pred_x_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
